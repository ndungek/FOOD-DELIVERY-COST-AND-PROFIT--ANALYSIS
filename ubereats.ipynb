{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<u>ONLINE FOOD DELIVERY PROFITABILITY ANALYSIS</u>**\n",
    "\n",
    "<span style=\"color: orange; font-style: italic;\">Maureen Ndunge Kitang'a</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PROJECT PROPOSAL**\n",
    "### *Executive Summary*\n",
    "\n",
    "Our analysis of Uber Eats data is geared towards extracting valuable insights into customer preferences within the food industry. We're looking at how much restaurants charge, their ratings, the types of food they offer, and where they're located. Our aim? Provide straightforward tips to help these places get noticed more on the platform and make more money.\n",
    "\n",
    "Analyzing this data helps us spot trends and patterns in the food scene. Our main goal is to provide practical recommendations that can reshape restaurant strategies and enhance their visibility on the Uber Eats platform.\n",
    "\n",
    "### *Problem Statement*\n",
    "Our main mission in this project is to provide practical guidance to clients planning to start a new restaurant chain or enhance the performance of their existing establishments. We're dealing with a widespread issue in the restaurant industry, where profit margins typically fall within the range of 10-20%. Our analysis is centered around exploring the current landscape of Uber Eats, aiming to uncover inventive strategies that can make restaurant businesses more attractive to both new and existing customers, ultimately driving higher profits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **WHY DOES THIS MATTER**\n",
    "The significance of this problem stems from the remarkable growth of online food ordering platforms, exemplified by Uber Eats' substantial transaction surge. In 2022, Uber Eats recorded a staggering USD 11 billion in revenue, marking a notable 31% increase from the previous year's revenue of $8.3 billion. Concurrently, there has been a steady 2% growth in user numbers, with a significant 10% increase in merchant participation in the US. These trends underscore the platform's rising popularity among both customers and merchants.\n",
    "\n",
    "Central to this challenge is understanding customer preferences across various dimensions, including preferred cuisines and menu diversity, within different regions. Thus, the pivotal question emerges: How can restaurants effectively analyze customer preferences to craft strategies that capitalize on the burgeoning potential of online food ordering platforms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA UNDERSTANDING**\n",
    "The primary dataset utilized in this analysis has information on various restaurants spread across the United States. Data sources were obtained through web scraping collected using Python libraries and the Uber Eats website.\n",
    "There are 2 datasets - Restaurants dataset, and the Menus dataset. For more in information on the [data](\"https://www.kaggle.com/datasets/ahmedshahriarsakib/uber-eats-usa-restaurants-menus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Dataset 1:Restaurants Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>position</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>ratings</th>\n",
       "      <th>category</th>\n",
       "      <th>price_range</th>\n",
       "      <th>full_address</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>PJ Fresh (224 Daniel Payne Drive)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burgers, American, Sandwiches</td>\n",
       "      <td>$</td>\n",
       "      <td>224 Daniel Payne Drive, Birmingham, AL, 35207</td>\n",
       "      <td>35207</td>\n",
       "      <td>33.562365</td>\n",
       "      <td>-86.830703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>J' ti`'z Smoothie-N-Coffee Bar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coffee and Tea, Breakfast and Brunch, Bubble Tea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1521 Pinson Valley Parkway, Birmingham, AL, 35217</td>\n",
       "      <td>35217</td>\n",
       "      <td>33.583640</td>\n",
       "      <td>-86.773330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>Philly Fresh Cheesesteaks (541-B Graymont Ave)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American, Cheesesteak, Sandwiches, Alcohol</td>\n",
       "      <td>$</td>\n",
       "      <td>541-B Graymont Ave, Birmingham, AL, 35204</td>\n",
       "      <td>35204</td>\n",
       "      <td>33.509800</td>\n",
       "      <td>-86.854640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>Papa Murphy's (1580 Montgomery Highway)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>$</td>\n",
       "      <td>1580 Montgomery Highway, Hoover, AL, 35226</td>\n",
       "      <td>35226</td>\n",
       "      <td>33.404439</td>\n",
       "      <td>-86.806614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>Nelson Brothers Cafe (17th St N)</td>\n",
       "      <td>4.7</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Breakfast and Brunch, Burgers, Sandwiches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314 17th St N, Birmingham, AL, 35203</td>\n",
       "      <td>35203</td>\n",
       "      <td>33.514730</td>\n",
       "      <td>-86.811700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  position                                            name  score  \\\n",
       "0   1        19               PJ Fresh (224 Daniel Payne Drive)    NaN   \n",
       "1   2         9                  J' ti`'z Smoothie-N-Coffee Bar    NaN   \n",
       "2   3         6  Philly Fresh Cheesesteaks (541-B Graymont Ave)    NaN   \n",
       "3   4        17         Papa Murphy's (1580 Montgomery Highway)    NaN   \n",
       "4   5       162                Nelson Brothers Cafe (17th St N)    4.7   \n",
       "\n",
       "   ratings                                          category price_range  \\\n",
       "0      NaN                     Burgers, American, Sandwiches           $   \n",
       "1      NaN  Coffee and Tea, Breakfast and Brunch, Bubble Tea         NaN   \n",
       "2      NaN        American, Cheesesteak, Sandwiches, Alcohol           $   \n",
       "3      NaN                                             Pizza           $   \n",
       "4     22.0         Breakfast and Brunch, Burgers, Sandwiches         NaN   \n",
       "\n",
       "                                        full_address zip_code        lat  \\\n",
       "0      224 Daniel Payne Drive, Birmingham, AL, 35207    35207  33.562365   \n",
       "1  1521 Pinson Valley Parkway, Birmingham, AL, 35217    35217  33.583640   \n",
       "2          541-B Graymont Ave, Birmingham, AL, 35204    35204  33.509800   \n",
       "3         1580 Montgomery Highway, Hoover, AL, 35226    35226  33.404439   \n",
       "4               314 17th St N, Birmingham, AL, 35203    35203  33.514730   \n",
       "\n",
       "         lng  \n",
       "0 -86.830703  \n",
       "1 -86.773330  \n",
       "2 -86.854640  \n",
       "3 -86.806614  \n",
       "4 -86.811700  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading data into a Pandas DataFrame\n",
    "restaurants = pd.read_csv(\"./data/restaurants.csv\")\n",
    "#Previewing the first few rows\n",
    "restaurants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows: 63469\n",
      "The number of columns:11\n"
     ]
    }
   ],
   "source": [
    "#Shape of the dataframe\n",
    "print(\"The number of rows: {}\".format(restaurants.shape[0]))\n",
    "\n",
    "print(\"The number of columns:{}\".format(restaurants.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63469 entries, 0 to 63468\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            63469 non-null  int64  \n",
      " 1   position      63469 non-null  int64  \n",
      " 2   name          63469 non-null  object \n",
      " 3   score         35302 non-null  float64\n",
      " 4   ratings       35302 non-null  float64\n",
      " 5   category      63384 non-null  object \n",
      " 6   price_range   52852 non-null  object \n",
      " 7   full_address  63016 non-null  object \n",
      " 8   zip_code      62952 non-null  object \n",
      " 9   lat           63469 non-null  float64\n",
      " 10  lng           63469 non-null  float64\n",
      "dtypes: float64(4), int64(2), object(5)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#General information about the dataset\n",
    "restaurants.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The restaurants dataset 63469 rows and 11 columns. The columns with missing data are `score`, `ratings`, `category`, `price_range`, `full_address`,and `zip_code`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Dataset 2:Menus Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>category</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5117212</th>\n",
       "      <td>63469</td>\n",
       "      <td>Other Essentials</td>\n",
       "      <td>Composition Notebook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.38 USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117213</th>\n",
       "      <td>63469</td>\n",
       "      <td>Other Essentials</td>\n",
       "      <td>Fancy Fest Savory Salmon - 3oz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.19 USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117214</th>\n",
       "      <td>63469</td>\n",
       "      <td>Other Essentials</td>\n",
       "      <td>Bicycle Playing Cards</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.83 USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117215</th>\n",
       "      <td>63469</td>\n",
       "      <td>Other Essentials</td>\n",
       "      <td>Tidy Cat Liter - 10lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.38 USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117216</th>\n",
       "      <td>63469</td>\n",
       "      <td>Other Essentials</td>\n",
       "      <td>7-Select Heavy Duty Foam Cooler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.8 USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         restaurant_id          category                             name  \\\n",
       "5117212          63469  Other Essentials             Composition Notebook   \n",
       "5117213          63469  Other Essentials   Fancy Fest Savory Salmon - 3oz   \n",
       "5117214          63469  Other Essentials            Bicycle Playing Cards   \n",
       "5117215          63469  Other Essentials           Tidy Cat Liter - 10lbs   \n",
       "5117216          63469  Other Essentials  7-Select Heavy Duty Foam Cooler   \n",
       "\n",
       "        description     price  \n",
       "5117212         NaN  4.38 USD  \n",
       "5117213         NaN  1.19 USD  \n",
       "5117214         NaN  3.83 USD  \n",
       "5117215         NaN  4.38 USD  \n",
       "5117216         NaN   6.8 USD  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the data into the Pandas DataFrame\n",
    "menus = pd.read_csv(\"./data/restaurant-menus.csv\")\n",
    "#Previewing the last few rows\n",
    "menus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows: 5117217\n",
      "The number of columns:5\n"
     ]
    }
   ],
   "source": [
    "#Shape of the dataframe\n",
    "print(\"The number of rows: {}\".format(menus.shape[0]))\n",
    "\n",
    "print(\"The number of columns:{}\".format(menus.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5117217 entries, 0 to 5117216\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   restaurant_id  int64 \n",
      " 1   category       object\n",
      " 2   name           object\n",
      " 3   description    object\n",
      " 4   price          object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 195.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#General information about the dataset\n",
    "menus.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA PREPARATION**\n",
    "\n",
    "During the Data Preparation phase, we will be performing a series of essential tasks to prepare our raw data for analysis. This phase includes the following key activities:\n",
    "\n",
    "*Merging Datasets:*\n",
    "We will combine multiple datasets, if available, to create a comprehensive dataset that encompasses all relevant information for our analysis. This may involve joining datasets based on common keys or merging them using appropriate techniques.\n",
    "\n",
    "*Deriving New Attributes:*\n",
    "To enhance the richness of our dataset and capture additional insights, we will create new attributes or features through feature engineering. This process involves transforming existing variables, generating new variables, or extracting valuable information from the data.\n",
    "\n",
    "*Data Cleaning:*\n",
    "Data cleaning is a crucial step that involves identifying and addressing various data quality issues, such as missing values, outliers, duplicates, and inconsistencies. We will employ techniques such as imputation, deletion, outlier detection, and data validation to ensure the integrity and quality of our dataset.\n",
    "\n",
    "*Exploratory Data Analysis (EDA):*\n",
    "EDA plays a vital role in understanding the underlying patterns, trends, and relationships within our data. We will perform exploratory data analysis to visualize distributions, examine correlations, detect patterns, and gain insights into the characteristics of our dataset. This will guide our subsequent analysis and decision-making processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA CLEANING**\n",
    ">> We will begin our Data Preparation phase by prioritizing data cleaning for individual datasets before merging. This approach allows us to address data inconsistencies, missing values, duplicates, outliers, and other quality issues specific to each dataset. By cleaning the datasets individually, we can ensure data integrity and consistency before merging. Additionally, considering differences in data sizes and structures among datasets, cleaning them separately facilitates more focused and efficient data cleaning efforts. Once each dataset is cleaned and standardized, we will proceed with merging them to create a comprehensive dataset for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df):\n",
    "   \n",
    "    missing_count = df.isnull().sum()  # Count missing values in each column\n",
    "    missing_percentage = (missing_count / len(df)) * 100  # Calculate percentage of missing values\n",
    "\n",
    "    # Create DataFrame to display missing values count and percentage\n",
    "    missing_values = pd.DataFrame({\n",
    "        'Missing Values': missing_count,\n",
    "        'Percentage': missing_percentage.round(2)\n",
    "    })\n",
    "    \n",
    "    return missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>position</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>28167</td>\n",
       "      <td>44.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratings</th>\n",
       "      <td>28167</td>\n",
       "      <td>44.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>85</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_range</th>\n",
       "      <td>10617</td>\n",
       "      <td>16.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_address</th>\n",
       "      <td>453</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_code</th>\n",
       "      <td>517</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lng</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing Values  Percentage\n",
       "id                         0        0.00\n",
       "position                   0        0.00\n",
       "name                       0        0.00\n",
       "score                  28167       44.38\n",
       "ratings                28167       44.38\n",
       "category                  85        0.13\n",
       "price_range            10617       16.73\n",
       "full_address             453        0.71\n",
       "zip_code                 517        0.81\n",
       "lat                        0        0.00\n",
       "lng                        0        0.00"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_missing_values(restaurants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Dealing with Missing Values*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns '`id`, `position`, `name`, `lat`, and `lng` have no missing values (0% missing). These columns are complete and do not require imputation or further handling for missing data.\n",
    "\n",
    "The columns `score` and `ratings` have a significant proportion of missing values, with approximately `44.38%`missing in each column. This suggests that a large portion of the data in these columns is missing.Given the significance of these features and their importance for the analysis, median imputation will be done to handle the missing values.\n",
    "\n",
    "The columns `category`, `price_range`, `full_address`, and `zip_code` have relatively fewer missing values, ranging from 0.13% to 16.73%, it's worth considering whether these missing values are significant enough to warrant deletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median imputation for 'score' and 'ratings' columns\n",
    "median_score = restaurants['score'].median()\n",
    "median_ratings = restaurants['ratings'].median()\n",
    "restaurants['score'] = restaurants['score'].fillna(median_score)\n",
    "restaurants['ratings'] = restaurants['ratings'].fillna(median_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletion of rows with missing values in 'category', 'price_range', 'full_address', and 'zip_code' columns\n",
    "restaurants.dropna(subset=['category', 'price_range', 'full_address', 'zip_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>restaurant_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>1452145</td>\n",
       "      <td>28.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Missing Values  Percentage\n",
       "restaurant_id               0        0.00\n",
       "category                    0        0.00\n",
       "name                        4        0.00\n",
       "description           1452145       28.38\n",
       "price                       0        0.00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_missing_values(menus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Dealing with Missing Values*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `description` column stands out as having a substantial number of missing values. To address this issue, rows with missing values in the 'description' column will be deleted to ensure data integrity.\n",
    "The other columns (`restaurant_id`, `category`, '`name`, and `price`) have either no missing values or a negligible number of missing values, suggesting that they are relatively complete and may not require extensive handling for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletion of rows with missing values in 'description' column\n",
    "menus.dropna(subset=['description','name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> In addition to handling missing values, ensuring the absence of duplicate data is crucial for maintaining the integrity and reliability of our datasets. Data duplicates can skew analysis results, leading to inaccurate insights and conclusions. Therefore, as part of our data cleaning process, we will systematically check for and remove any duplicate entries within each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "def check_duplicates(df):\n",
    "    \n",
    "    duplicates = df.duplicated().any()\n",
    "    return duplicates\n",
    "\n",
    "# Check for duplicates in the restaurants DataFrame\n",
    "has_duplicates = check_duplicates(restaurants)\n",
    "\n",
    "# Print the result\n",
    "if has_duplicates:\n",
    "    print(\"Duplicates found in the DataFrame.\")\n",
    "else:\n",
    "    print(\"No duplicates found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates found in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in the restaurants DataFrame\n",
    "has_duplicates = check_duplicates(menus)\n",
    "\n",
    "# Print the result\n",
    "if has_duplicates:\n",
    "    print(\"Duplicates found in the DataFrame.\")\n",
    "else:\n",
    "    print(\"No duplicates found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> Upon examining the menus DataFrame, it appears that duplicate rows have been detected. To further investigate the extent of duplication and gain insight into the duplicated data, we can inspect the DataFrame containing these duplicate rows. This will allow us to identify the specific duplicated entries and assess any patterns or inconsistencies present in the data. By closely examining these duplicates, we can make informed decisions regarding the appropriate actions to take, such as removal or additional data cleaning measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates found in the DataFrame:\n",
      "         restaurant_id          category  \\\n",
      "379                  7  Nigiri / Sashimi   \n",
      "380                  7  Nigiri / Sashimi   \n",
      "381                  7  Nigiri / Sashimi   \n",
      "388                  7  Nigiri / Sashimi   \n",
      "10677              165         Beverages   \n",
      "...                ...               ...   \n",
      "5116337          63449   Spring & Summer   \n",
      "5116339          63449   Spring & Summer   \n",
      "5116341          63449   Spring & Summer   \n",
      "5117028          63469              Food   \n",
      "5117040          63469              Food   \n",
      "\n",
      "                                                      name  \\\n",
      "379                                            Tuna Tataki   \n",
      "380                                                 Amaebi   \n",
      "381                                                 Amaebi   \n",
      "388                                            Tuna Tataki   \n",
      "10677                                  Strawberry Lemonade   \n",
      "...                                                    ...   \n",
      "5116337  Moon & Stars Satin Trim Blanket And Animal Set...   \n",
      "5116339            Moon & Stars My Favorite Plush - 1.0 ea   \n",
      "5116341  Moon & Stars Satin Trim Blanket And Animal Set...   \n",
      "5117028                                 Mini Tacos - 10 pc   \n",
      "5117040                                 Mini Tacos - 10 pc   \n",
      "\n",
      "                                               description      price  \n",
      "379                                           Seared tuna.    6.0 USD  \n",
      "380                                          Sweet shrimp.    7.0 USD  \n",
      "381                                          Sweet shrimp.    7.0 USD  \n",
      "388                                           Seared tuna.    6.0 USD  \n",
      "10677    Chilled lemonade infused with the sweet taste ...   3.83 USD  \n",
      "...                                                    ...        ...  \n",
      "5116337  This baby item combines cute plush toy and nic...  15.73 USD  \n",
      "5116339  It is a warm & cozy cuddle pal that keeps your...  13.63 USD  \n",
      "5116341  This baby item combines cute plush toy and nic...  15.73 USD  \n",
      "5117028                                           10 Count   5.32 USD  \n",
      "5117040                                           10 Count   5.32 USD  \n",
      "\n",
      "[41420 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in the 'menus' DataFrame across all columns\n",
    "duplicate_menus = menus[menus.duplicated(keep=False)]\n",
    "\n",
    "# Display duplicate rows for inspection\n",
    "print(\"Duplicates found in the DataFrame:\")\n",
    "print(duplicate_menus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed. New DataFrame shape: (3644316, 5)\n"
     ]
    }
   ],
   "source": [
    "# Keep the first occurrence of each duplicated row and drop the rest\n",
    "menus_cleaned = menus.drop_duplicates(keep='first')\n",
    "\n",
    "# Confirm that duplicates have been removed\n",
    "print(\"Duplicates removed. New DataFrame shape:\", menus_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Merging the Datasets*\n",
    ">> Merging datasets involves combining multiple datasets into a single comprehensive dataset. This process is essential for integrating data from different sources to perform unified analyses. In our case, we have two datasets: one containing information about restaurants and another containing menu data. Merging these datasets allows us to create a unified dataset that includes both restaurant details and their respective menus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the restaurant dataset with the menu dataset\n",
    "merged_data=restaurants.merge(menus, left_on='id', right_on='restaurant_id', how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of merged dataset: (3666905, 16)\n",
      " id  position                            name_x  score  ratings                    category_x price_range                                  full_address zip_code       lat        lng  restaurant_id        category_y                              name_y description     price\n",
      "1.0      19.0 PJ Fresh (224 Daniel Payne Drive)    4.6     52.0 Burgers, American, Sandwiches           $ 224 Daniel Payne Drive, Birmingham, AL, 35207    35207 33.562365 -86.830703            1.0 Extra Large Pizza             Extra Large Meat Lovers  Whole pie. 15.99 USD\n",
      "1.0      19.0 PJ Fresh (224 Daniel Payne Drive)    4.6     52.0 Burgers, American, Sandwiches           $ 224 Daniel Payne Drive, Birmingham, AL, 35207    35207 33.562365 -86.830703            1.0 Extra Large Pizza                 Extra Large Supreme  Whole pie. 15.99 USD\n",
      "1.0      19.0 PJ Fresh (224 Daniel Payne Drive)    4.6     52.0 Burgers, American, Sandwiches           $ 224 Daniel Payne Drive, Birmingham, AL, 35207    35207 33.562365 -86.830703            1.0 Extra Large Pizza               Extra Large Pepperoni  Whole pie. 14.99 USD\n",
      "1.0      19.0 PJ Fresh (224 Daniel Payne Drive)    4.6     52.0 Burgers, American, Sandwiches           $ 224 Daniel Payne Drive, Birmingham, AL, 35207    35207 33.562365 -86.830703            1.0 Extra Large Pizza Extra Large BBQ Chicken &amp; Bacon   Whole Pie 15.99 USD\n",
      "1.0      19.0 PJ Fresh (224 Daniel Payne Drive)    4.6     52.0 Burgers, American, Sandwiches           $ 224 Daniel Payne Drive, Birmingham, AL, 35207    35207 33.562365 -86.830703            1.0 Extra Large Pizza                Extra Large 5 Cheese  Whole pie. 14.99 USD\n"
     ]
    }
   ],
   "source": [
    "# Display the merged dataset\n",
    "print(\"Shape of merged dataset:\", merged_data.shape)\n",
    "# Display the first few rows of the merged dataset in table format\n",
    "print(merged_data.head().to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
